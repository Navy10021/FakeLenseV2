{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FakeLenseV2 - Training Guide\n",
    "\n",
    "This notebook demonstrates how to train a FakeLenseV2 model from scratch.\n",
    "\n",
    "## Topics Covered\n",
    "1. Data preparation\n",
    "2. Configuration setup\n",
    "3. Training the model\n",
    "4. Monitoring training progress\n",
    "5. Evaluating results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from code.train import Trainer\n",
    "from code.agents.fake_news_agent import FakeNewsAgent\n",
    "from code.utils.feature_extraction import FeatureExtractor\n",
    "from code.utils.config import get_default_config\n",
    "from code.models.vectorizer import BaseVectorizer\n",
    "\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Training Data\n",
    "\n",
    "Your training data should be in JSON format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example training data structure\n",
    "example_data = [\n",
    "    {\n",
    "        \"text\": \"The government announces new policy.\",\n",
    "        \"source_reliability\": \"Reuters\",\n",
    "        \"social_reactions\": 5000,\n",
    "        \"label\": 2  # 0=Fake, 1=Suspicious, 2=Real\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Aliens discovered in local park!\",\n",
    "        \"source_reliability\": \"Unknown Blog\",\n",
    "        \"social_reactions\": 100000,\n",
    "        \"label\": 0\n",
    "    }\n",
    "]\n",
    "\n",
    "# Save as JSON (optional)\n",
    "# with open('../../data/my_train_data.json', 'w') as f:\n",
    "#     json.dump(example_data, f, indent=2)\n",
    "\n",
    "print(\"Data format example:\")\n",
    "print(json.dumps(example_data[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your training data\n",
    "with open(\"../../data/train_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(train_data)} training samples\")\n",
    "print(f\"\\nFirst sample:\")\n",
    "print(json.dumps(train_data[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default configuration\n",
    "config = get_default_config()\n",
    "\n",
    "# Customize for quick training (for demonstration)\n",
    "config.update({\n",
    "    \"num_episodes\": 10,       # Number of training episodes\n",
    "    \"batch_size\": 32,          # Batch size for replay\n",
    "    \"learning_rate\": 0.001,    # Learning rate\n",
    "    \"patience\": 5,             # Early stopping patience\n",
    "    \"use_residual\": True,      # Use Residual DQN\n",
    "})\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "for key, value in config.items():\n",
    "    if key in [\"num_episodes\", \"batch_size\", \"learning_rate\", \"patience\"]:\n",
    "        print(f\"  {key:20s}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vectorizer and feature extractor\n",
    "vectorizer = BaseVectorizer(model_name=\"bert-base-uncased\")\n",
    "feature_extractor = FeatureExtractor(vectorizer=vectorizer)\n",
    "\n",
    "# Initialize agent\n",
    "state_size = 770  # 768 (BERT) + 2 (metadata)\n",
    "action_size = 3   # Fake, Suspicious, Real\n",
    "\n",
    "agent = FakeNewsAgent(state_size, action_size, config)\n",
    "\n",
    "print(\"✅ Components initialized\")\n",
    "print(f\"   State size: {state_size}\")\n",
    "print(f\"   Action size: {action_size}\")\n",
    "print(f\"   Model: {agent.model.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Trainer and Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(agent, feature_extractor, config)\n",
    "\n",
    "# Start training\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "trainer.train(\n",
    "    train_data,\n",
    "    num_episodes=config[\"num_episodes\"],\n",
    "    patience=config[\"patience\"]\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Progress\n",
    "\n",
    "The training curve is automatically saved to `models/training_curve.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Display training curve\n",
    "try:\n",
    "    display(Image(filename='../../models/training_curve.png'))\n",
    "except:\n",
    "    print(\"Training curve not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code.inference import InferenceEngine\n",
    "\n",
    "# Load the trained model\n",
    "engine = InferenceEngine(\"../../models/best_model.pth\", config)\n",
    "\n",
    "# Test prediction\n",
    "test_text = \"Scientists make breakthrough discovery in renewable energy.\"\n",
    "prediction = engine.predict(\n",
    "    text=test_text,\n",
    "    source=\"Reuters\",\n",
    "    social_reactions=5000\n",
    ")\n",
    "\n",
    "labels = {0: \"Fake News\", 1: \"Suspicious News\", 2: \"Real News\"}\n",
    "print(f\"\\nTest Prediction:\")\n",
    "print(f\"Text: {test_text}\")\n",
    "print(f\"Result: {labels[prediction]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Configuration\n",
    "\n",
    "Save your training configuration for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save configuration\n",
    "with open('../../models/training_config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"✅ Configuration saved to models/training_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "- **Evaluate**: Use the evaluation notebook to assess performance\n",
    "- **Fine-tune**: Adjust hyperparameters and retrain\n",
    "- **Deploy**: See API deployment guide\n",
    "\n",
    "## Tips for Better Training\n",
    "\n",
    "1. **More Data**: Use larger datasets for better generalization\n",
    "2. **Balanced Dataset**: Ensure equal representation of all classes\n",
    "3. **Hyperparameter Tuning**: Experiment with learning rate, batch size\n",
    "4. **Longer Training**: Increase num_episodes for better convergence\n",
    "5. **GPU**: Use GPU for faster training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
